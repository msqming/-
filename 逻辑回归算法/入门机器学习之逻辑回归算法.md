## 学习目标
* 了解 逻辑回归 的理论
* 了解 逻辑回归 的损失函数
* 了解 逻辑回归 的决策边界
* 掌握 逻辑回归 的 sklearn 函数调用使用并将其运用到鸢尾花数据集预测

## 介绍
**逻辑回归**（Logistic regression，简称LR），它既可以看做是一个分类算法，也可以看做是一个回归算法，通常是作为分类算法用。

逻辑回归解决分类问题的原理是：将样本的特征和样本发生的概率联系起来；由于概率是一个数，也可以管它叫作是回归问题。

## 逻辑回归模型
### Sigmoid 函数
逻辑回归既然是一个解决概率的分类问题的算法，我们知道概率问题的值域是在(0,1)之间，所以应运而生了 *Sigmoid函数*。

![Sigmoid模型](https://github.com/msqming/playML/blob/master/img/01.png)

通过上面的 *Sigmoid* 数学公式，我们可以通过代码来绘制 *Sigmoid函数* 图像
```
import numpy as np
import matplotlib.pyplot as plt


def sigmoid(t):
    """ Sigmoid 函数 """
    return 1 / (1 + np.exp(-t))


# 生成测试数据 -10到10之间的500个数据
x = np.linspace(-10, 10, 500)
y = sigmoid(x)

# 绘制图像
plt.plot(x, y)
plt.show()
```

![Sigmoid图像](https://github.com/msqming/playML/blob/master/img/LR02.jpg)
![Sigmoid图像](https://github.com/msqming/playML/blob/master/img/LR03.jpg)
通过上面的图像可以看到，最左端的数据是无限趋近于0，最右端的数据是无限趋近于1的，所以我们可以得出图上的这个曲线的值域是(0,1)，是非常适合用来表达概率的。

当 *t >= 0*时, *p >= 0.5*, 其对应的y值我们可以判定为类别1；
当 *t < 0*时, *p < 0.5*, 其对应的y值我们可以判定为类别2；
这就是逻辑回归里的二分类问题。
