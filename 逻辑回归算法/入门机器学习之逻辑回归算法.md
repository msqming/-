## 学习目标
* 了解 逻辑回归 的理论
* 掌握 逻辑回归 的 sklearn 函数调用使用并将其运用到鸢尾花数据集预测

## 介绍
**逻辑回归**（Logistic regression，简称LR），它既可以看做是一个分类算法，也可以看做是一个回归算法，通常是作为分类算法用。

逻辑回归解决分类问题的原理是：将样本的特征和样本发生的概率联系起来；由于概率是一个数，也可以管它叫作是回归问题。

## 逻辑回归模型
### Sigmoid 函数
逻辑回归既然是一个解决概率的分类问题的算法，我们知道概率问题的值域是在(0,1)之间，所以应运而生了 *Sigmoid函数*。

![Sigmoid模型](https://github.com/msqming/playML/blob/master/img/01.png)

通过上面的 *Sigmoid* 数学公式，我们可以通过代码来绘制 *Sigmoid函数* 图像
```
import numpy as np
import matplotlib.pyplot as plt


def sigmoid(t):
    """ Sigmoid 函数 """
    return 1 / (1 + np.exp(-t))


# 生成测试数据 -10到10之间的500个数据
x = np.linspace(-10, 10, 500)
y = sigmoid(x)

# 绘制图像
plt.plot(x, y)
plt.show()
```

![Sigmoid图像](https://github.com/msqming/playML/blob/master/img/LR02.jpg)
![Sigmoid图像](https://github.com/msqming/playML/blob/master/img/LR03.jpg)  
通过上面的图像可以看到，最左端的数据是无限趋近于0，最右端的数据是无限趋近于1的，所以我们可以得出图上的这个曲线的值域是(0,1)，是非常适合用来表达概率的。  

当 *t >= 0*时, *p >= 0.5*, 其对应的y值我们可以判定为类别1，  
当 *t < 0*时, *p < 0.5*, 其对应的y值我们可以判定为类别2，  
这就是逻辑回归里的二分类问题。  

## sklearn中的逻辑回归代码实现
```
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from matplotlib.colors import ListedColormap
from sklearn.multiclass import OneVsOneClassifier

# 鸢尾花数据集
iris = datasets.load_iris()
# 去数据集中的前两列属性值
X = iris.data[:, :2]
y = iris.target

# 分割测试数据集和训练数据集
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)

log_reg = LogisticRegression()
# 利用训练数据集进行训练
ovo = OneVsOneClassifier(log_reg)
ovo.fit(X_train, y_train)
print('数据集前两个属性的准确率',ovo.score(X_test, y_test))  # 0.84


def plot_decision_boundary(model, axis):
    """ 画图函数 """
    x0, x1 = np.meshgrid(
        np.linspace(axis[0], axis[1], int((axis[1] - axis[0]) * 100)).reshape(-1, 1),
        np.linspace(axis[2], axis[3], int((axis[3] - axis[2]) * 100)).reshape(-1, 1),
    )
    X_new = np.c_[x0.ravel(), x1.ravel()]

    y_predict = model.predict(X_new)
    zz = y_predict.reshape(x0.shape)

    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])

    plt.contourf(x0, x1, zz, linewidth=5, cmap=custom_cmap)


plot_decision_boundary(ovo, axis=[4, 8.5, 1.5, 4.5])
plt.scatter(X[y == 0, 0], X[y == 0, 1])
plt.scatter(X[y == 1, 0], X[y == 1, 1])
plt.scatter(X[y == 2, 0], X[y == 2, 1])
plt.show()

X_all = iris.data
y_all = iris.target

# 分割测试数据集和训练数据集
X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, random_state=666)

log_reg = LogisticRegression()
# 利用训练数据集进行训练
ovo = OneVsOneClassifier(log_reg)
ovo.fit(X_train, y_train)
print('数据集前全部属性的准确率',ovo.score(X_test, y_test))  # 1.0
```
下图是只取了数据集前两个属性所得的图像  
从代码可以看到，当测试的时候获取了数据值所有属性，准确率为 1
![Sigmoid图像](https://github.com/msqming/playML/blob/master/img/LR04.jpg) 
